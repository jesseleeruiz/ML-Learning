{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on the Snacks Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 32\n",
    "image_height = 32\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/matthijs/anaconda3/envs/kerasenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(image_height, image_width, 3)))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                61460     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 61,460\n",
      "Trainable params: 61,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizers.Adam(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"snacks/\"\n",
    "train_data_dir = images_dir + \"train/\"\n",
    "val_data_dir = images_dir + \"val/\"\n",
    "test_data_dir = images_dir + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(train_data_dir + \"apple/cecd90f5d46f57b0.jpg\", \n",
    "                     target_size=(image_width, image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x63b26fc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[215., 215., 217.],\n",
       "        [211., 211., 211.],\n",
       "        [207., 207., 207.],\n",
       "        ...,\n",
       "        [152., 150., 137.],\n",
       "        [148., 146., 133.],\n",
       "        [149., 147., 132.]],\n",
       "\n",
       "       [[213., 213., 215.],\n",
       "        [210., 210., 210.],\n",
       "        [207., 207., 207.],\n",
       "        ...,\n",
       "        [157., 150., 134.],\n",
       "        [153., 146., 130.],\n",
       "        [153., 146., 128.]],\n",
       "\n",
       "       [[219., 220., 222.],\n",
       "        [220., 221., 223.],\n",
       "        [218., 219., 221.],\n",
       "        ...,\n",
       "        [156., 149., 133.],\n",
       "        [152., 145., 129.],\n",
       "        [153., 146., 130.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[172.,  50.,  65.],\n",
       "        [131.,  34.,  41.],\n",
       "        [ 95.,  23.,  27.],\n",
       "        ...,\n",
       "        [193., 121.,  81.],\n",
       "        [181.,  90.,  63.],\n",
       "        [140.,  68.,  46.]],\n",
       "\n",
       "       [[168.,  54.,  64.],\n",
       "        [123.,  32.,  41.],\n",
       "        [118.,  33.,  40.],\n",
       "        ...,\n",
       "        [177., 118.,  74.],\n",
       "        [163.,  64.,  45.],\n",
       "        [136.,  49.,  39.]],\n",
       "\n",
       "       [[165.,  55.,  66.],\n",
       "        [132.,  35.,  46.],\n",
       "        [120.,  29.,  38.],\n",
       "        ...,\n",
       "        [172., 116.,  67.],\n",
       "        [155.,  89.,  55.],\n",
       "        [111.,  25.,  24.]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(image):\n",
    "    return image / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = normalize_pixels(x)\n",
    "x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.6862745 ,  0.6862745 ,  0.7019608 ],\n",
       "         [ 0.654902  ,  0.654902  ,  0.654902  ],\n",
       "         [ 0.62352943,  0.62352943,  0.62352943],\n",
       "         ...,\n",
       "         [ 0.19215691,  0.17647064,  0.07450986],\n",
       "         [ 0.16078436,  0.14509809,  0.04313731],\n",
       "         [ 0.1686275 ,  0.15294123,  0.03529418]],\n",
       "\n",
       "        [[ 0.67058825,  0.67058825,  0.6862745 ],\n",
       "         [ 0.64705884,  0.64705884,  0.64705884],\n",
       "         [ 0.62352943,  0.62352943,  0.62352943],\n",
       "         ...,\n",
       "         [ 0.2313726 ,  0.17647064,  0.05098045],\n",
       "         [ 0.20000005,  0.14509809,  0.0196079 ],\n",
       "         [ 0.20000005,  0.14509809,  0.00392163]],\n",
       "\n",
       "        [[ 0.7176471 ,  0.7254902 ,  0.7411765 ],\n",
       "         [ 0.7254902 ,  0.73333335,  0.7490196 ],\n",
       "         [ 0.70980394,  0.7176471 ,  0.73333335],\n",
       "         ...,\n",
       "         [ 0.22352946,  0.1686275 ,  0.04313731],\n",
       "         [ 0.19215691,  0.13725495,  0.01176476],\n",
       "         [ 0.20000005,  0.14509809,  0.0196079 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.34901965, -0.60784316, -0.49019605],\n",
       "         [ 0.02745104, -0.73333335, -0.6784314 ],\n",
       "         [-0.25490195, -0.81960785, -0.7882353 ],\n",
       "         ...,\n",
       "         [ 0.5137255 , -0.05098039, -0.36470586],\n",
       "         [ 0.41960788, -0.29411763, -0.5058824 ],\n",
       "         [ 0.09803927, -0.46666664, -0.6392157 ]],\n",
       "\n",
       "        [[ 0.3176471 , -0.5764706 , -0.4980392 ],\n",
       "         [-0.03529412, -0.7490196 , -0.6784314 ],\n",
       "         [-0.0745098 , -0.7411765 , -0.6862745 ],\n",
       "         ...,\n",
       "         [ 0.38823533, -0.0745098 , -0.41960782],\n",
       "         [ 0.27843142, -0.4980392 , -0.64705884],\n",
       "         [ 0.06666672, -0.6156863 , -0.69411767]],\n",
       "\n",
       "        [[ 0.2941177 , -0.5686275 , -0.4823529 ],\n",
       "         [ 0.03529418, -0.7254902 , -0.6392157 ],\n",
       "         [-0.05882353, -0.77254903, -0.7019608 ],\n",
       "         ...,\n",
       "         [ 0.34901965, -0.09019607, -0.47450978],\n",
       "         [ 0.21568632, -0.30196077, -0.5686275 ],\n",
       "         [-0.12941176, -0.8039216 , -0.8117647 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.098154075"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52534205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction with the untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13864781 0.05875769 0.01606221 0.06414423 0.03024339 0.01983942\n",
      "  0.07829567 0.00972674 0.01924711 0.15570098 0.02290487 0.01670541\n",
      "  0.07535105 0.14817312 0.0126835  0.01829712 0.04879378 0.01755643\n",
      "  0.02502218 0.02384727]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15570098"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(preprocessing_function=normalize_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4838 images belonging to 20 classes.\n",
      "Found 955 images belonging to 20 classes.\n",
      "Found 952 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(image_width, image_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode=\"categorical\",\n",
    "                    shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "                    val_data_dir,\n",
    "                    target_size=(image_width, image_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode=\"categorical\",\n",
    "                    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "                    test_data_dir,\n",
    "                    target_size=(image_width, image_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode=\"categorical\",\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 3)\n",
      "(64, 20)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(train_generator)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0,\n",
       " 'banana': 1,\n",
       " 'cake': 2,\n",
       " 'candy': 3,\n",
       " 'carrot': 4,\n",
       " 'cookie': 5,\n",
       " 'doughnut': 6,\n",
       " 'grape': 7,\n",
       " 'hot dog': 8,\n",
       " 'ice cream': 9,\n",
       " 'juice': 10,\n",
       " 'muffin': 11,\n",
       " 'orange': 12,\n",
       " 'pineapple': 13,\n",
       " 'popcorn': 14,\n",
       " 'pretzel': 15,\n",
       " 'salad': 16,\n",
       " 'strawberry': 17,\n",
       " 'waffle': 18,\n",
       " 'watermelon': 19}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apple',\n",
       " 1: 'banana',\n",
       " 2: 'cake',\n",
       " 3: 'candy',\n",
       " 4: 'carrot',\n",
       " 5: 'cookie',\n",
       " 6: 'doughnut',\n",
       " 7: 'grape',\n",
       " 8: 'hot dog',\n",
       " 9: 'ice cream',\n",
       " 10: 'juice',\n",
       " 11: 'muffin',\n",
       " 12: 'orange',\n",
       " 13: 'pineapple',\n",
       " 14: 'popcorn',\n",
       " 15: 'pretzel',\n",
       " 16: 'salad',\n",
       " 17: 'strawberry',\n",
       " 18: 'waffle',\n",
       " 19: 'watermelon'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2class = {v:k for k,v in train_generator.class_indices.items()}\n",
    "index2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strawberry'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2class[np.argmax(y[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the untrained model on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2943690844944546, 0.06197479010379615]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.298702133840251, 0.05353451837139122]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(train_generator, steps=len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.3391019656396037, 0.04502617801242162]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(val_generator, steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "76/76 [==============================] - 33s 429ms/step - loss: 3.0703 - acc: 0.1099 - val_loss: 3.1100 - val_acc: 0.1152\n",
      "Epoch 2/5\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 2.7117 - acc: 0.2078 - val_loss: 3.0585 - val_acc: 0.1246\n",
      "Epoch 3/5\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 2.4977 - acc: 0.2646 - val_loss: 3.1021 - val_acc: 0.1204\n",
      "Epoch 4/5\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 2.3495 - acc: 0.3134 - val_loss: 3.1261 - val_acc: 0.1246\n",
      "Epoch 5/5\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 2.2028 - acc: 0.3631 - val_loss: 3.1804 - val_acc: 0.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6442b3748>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=len(val_generator),\n",
    "                    epochs=5,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 28s 372ms/step - loss: 2.0620 - acc: 0.4093 - val_loss: 3.1856 - val_acc: 0.1141\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 1.9758 - acc: 0.4453 - val_loss: 3.2545 - val_acc: 0.1058\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.8942 - acc: 0.4736 - val_loss: 3.2362 - val_acc: 0.1351\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.8108 - acc: 0.4960 - val_loss: 3.2788 - val_acc: 0.1277\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.7322 - acc: 0.5246 - val_loss: 3.2934 - val_acc: 0.1246\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 3s 41ms/step - loss: 1.6665 - acc: 0.5440 - val_loss: 3.3457 - val_acc: 0.1236\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.6005 - acc: 0.5774 - val_loss: 3.3879 - val_acc: 0.1026\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.5361 - acc: 0.5931 - val_loss: 3.4416 - val_acc: 0.1246\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.4809 - acc: 0.6095 - val_loss: 3.4757 - val_acc: 0.1131\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.4275 - acc: 0.6267 - val_loss: 3.4892 - val_acc: 0.1267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x63b90f2e8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=len(val_generator),\n",
    "                    epochs=10,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5019439208407364, 0.11659663870241962]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.3760 - acc: 0.6388 - val_loss: 3.5221 - val_acc: 0.1079\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.3229 - acc: 0.6603 - val_loss: 3.5990 - val_acc: 0.1131\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.2889 - acc: 0.6746 - val_loss: 3.6058 - val_acc: 0.1037\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 3s 36ms/step - loss: 1.2519 - acc: 0.6956 - val_loss: 3.6024 - val_acc: 0.1298\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 3s 37ms/step - loss: 1.2255 - acc: 0.6968 - val_loss: 3.6954 - val_acc: 0.1047\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.1756 - acc: 0.7208 - val_loss: 3.7533 - val_acc: 0.1047\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 3s 38ms/step - loss: 1.1472 - acc: 0.7268 - val_loss: 3.7801 - val_acc: 0.1110\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.1100 - acc: 0.7392 - val_loss: 3.7392 - val_acc: 0.1246\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 3s 40ms/step - loss: 1.0946 - acc: 0.7387 - val_loss: 3.8165 - val_acc: 0.1120\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 3s 39ms/step - loss: 1.0357 - acc: 0.7596 - val_loss: 3.8335 - val_acc: 0.1099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6442f8d68>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=len(val_generator),\n",
    "                    epochs=10,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8502991019176838, 0.11449579841324262]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
