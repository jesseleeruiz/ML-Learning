{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset. It contains translations from English to Spanish, so swap the order of the phrases. Also add `\\t` and `\\n` as the start and stop tokens in the target sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \"\\t\"\n",
    "stop_token = \"\\n\"\n",
    "\n",
    "with open(\"data/spa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    samples = f.read().split(\"\\n\")\n",
    "\n",
    "samples = [sample.strip().split(\"\\t\")\n",
    "           for sample in samples if len(sample.strip()) > 0]\n",
    "\n",
    "samples = [(es, start_token + en + stop_token)\n",
    "           for en, es in samples if len(es) < 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99423"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ve.', '\\tGo.\\n'), ('Vete.', '\\tGo.\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(samples[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlpenv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, valid_samples = train_test_split(samples, train_size=.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the training vocabulary. Those are the only tokens you can trust the model will know how to handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 101\n",
      "Output vocab size: 87\n"
     ]
    }
   ],
   "source": [
    "in_vocab = set()\n",
    "out_vocab = set()\n",
    "\n",
    "for in_seq, out_seq in train_samples:\n",
    "    in_vocab.update(in_seq)\n",
    "    out_vocab.update(out_seq)\n",
    "    \n",
    "in_vocab_size = len(in_vocab)\n",
    "out_vocab_size = len(out_vocab)\n",
    "\n",
    "print(\"Input vocab size:\", in_vocab_size)\n",
    "print(\"Output vocab size:\", out_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '°', 'º', '»', '¿', 'Á', 'É', 'Ó', 'Ú', 'á', 'è', 'é', 'í', 'ñ', 'ó', 'ö', 'ú', 'ü', 'ś', 'с', '—', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(in_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '$', '%', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'á', 'ã', 'è', 'é', 'ö', '‘', '’', '₂', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(out_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through validation set and remove any tokens not present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_samples = []\n",
    "for in_seq, out_seq in valid_samples:\n",
    "    tmp_in_seq = [c for c in in_seq if c in in_vocab]\n",
    "    tmp_out_seq = [c for c in out_seq if c in out_vocab]\n",
    "\n",
    "    tmp_samples.append((\"\".join(tmp_in_seq), \"\".join(tmp_out_seq)))\n",
    "    \n",
    "valid_samples = tmp_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build sequence-to-sequence model with bidirectional encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Concatenate, Dense, Input, GRU, Masking\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoder with two GRU layers, each processing the input in a different direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "\n",
    "encoder_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "encoder_mask = Masking(name=\"encoder_mask\")(encoder_in)\n",
    "\n",
    "fwd_enc_gru = GRU(latent_dim, recurrent_dropout=0.3, name=\"fwd_enc_gru\")\n",
    "rev_enc_gru = GRU(latent_dim, go_backwards=True, recurrent_dropout=0.3, name=\"rev_enc_gru\")\n",
    "fwd_enc_out = fwd_enc_gru(encoder_mask)\n",
    "rev_enc_out = rev_enc_gru(encoder_mask)\n",
    "\n",
    "encoder_out = Concatenate(name=\"encoder_out\")([fwd_enc_out, rev_enc_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder's input dimensions are twice as big as the encoder's output dimensions because you combine the forward and reverse outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_latent_dim = latent_dim * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_in = Input(shape=(None, out_vocab_size), name=\"decoder_in\")\n",
    "\n",
    "decoder_mask = Masking(name=\"decoder_mask\")(decoder_in)\n",
    "decoder_gru = GRU(decoder_latent_dim, return_sequences=True,\n",
    "                  return_state=True, dropout=0.2, recurrent_dropout=0.3,\n",
    "                  name=\"decoder_gru\")\n",
    "decoder_gru_out, _ = decoder_gru(decoder_mask, initial_state=encoder_out)\n",
    "decoder_dense = Dense(out_vocab_size, activation=\"softmax\", name=\"decoder_out\")\n",
    "decoder_out = decoder_dense(decoder_gru_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = Model([encoder_in, decoder_in], decoder_out)\n",
    "seq2seq_model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_in (InputLayer)         (None, None, 101)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mask (Masking)          (None, None, 101)    0           encoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_in (InputLayer)         (None, None, 87)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fwd_enc_gru (GRU)               (None, 512)          943104      encoder_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "rev_enc_gru (GRU)               (None, 512)          943104      encoder_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_mask (Masking)          (None, None, 87)     0           decoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_out (Concatenate)       (None, 1024)         0           fwd_enc_gru[0][0]                \n",
      "                                                                 rev_enc_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 1024), 3416064     decoder_mask[0][0]               \n",
      "                                                                 encoder_out[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_out (Dense)             (None, None, 87)     89175       decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,391,447\n",
      "Trainable params: 5,391,447\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create maps to convert characters to and from ints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_token2int = {token : i for i, token in enumerate(sorted(in_vocab))}\n",
    "out_token2int = {token : i for i, token in enumerate(sorted(out_vocab))}\n",
    "out_int2token = {i : token for (token, i) in out_token2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions for one-hot encoding sequences for use with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_batch_storage(batch_size, in_seq_len, out_seq_len):\n",
    "    \n",
    "    enc_in_seqs = np.zeros(\n",
    "        (batch_size, in_seq_len, in_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_in_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_out_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "        \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(samples):\n",
    "    batch_size = len(samples)\n",
    "    max_in_length = max([len(seq) for seq, _ in samples])\n",
    "    max_out_length = max([len(seq) for _, seq in samples])\n",
    "\n",
    "    enc_in_seqs, dec_in_seqs, dec_out_seqs = make_batch_storage(\n",
    "        batch_size, max_in_length, max_out_length)\n",
    "    \n",
    "    for i, (in_seq, out_seq) in enumerate(samples):\n",
    "        for time_step, token in enumerate(in_seq):\n",
    "            enc_in_seqs[i, time_step, in_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq):\n",
    "            dec_in_seqs[i, time_step, out_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq[1:]):\n",
    "            dec_out_seqs[i, time_step, out_token2int[token]] = 1\n",
    "            \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_util import Seq2SeqBatchGenerator\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = Seq2SeqBatchGenerator(train_samples, batch_size, encode_batch)\n",
    "valid_generator = Seq2SeqBatchGenerator(valid_samples, batch_size, encode_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning:\n",
    "\n",
    "Running the following cell can take a long time. If you are just experimenting, consider changing the `epochs` value to something small, from `1` to `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 1.7318 - val_loss: 1.1955\n",
      "Epoch 2/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 1.2402 - val_loss: 0.9769\n",
      "Epoch 3/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 1.0798 - val_loss: 0.8643\n",
      "Epoch 4/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.9880 - val_loss: 0.7926\n",
      "Epoch 5/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.9271 - val_loss: 0.7459\n",
      "Epoch 6/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.8817 - val_loss: 0.7073\n",
      "Epoch 7/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.8455 - val_loss: 0.6788\n",
      "Epoch 8/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.8166 - val_loss: 0.6527\n",
      "Epoch 9/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.7925 - val_loss: 0.6316\n",
      "Epoch 10/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.7716 - val_loss: 0.6141\n",
      "Epoch 11/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.7536 - val_loss: 0.6006\n",
      "Epoch 12/500\n",
      "1247/1247 [==============================] - 96s 77ms/step - loss: 0.7375 - val_loss: 0.5877\n",
      "Epoch 13/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.7227 - val_loss: 0.5714\n",
      "Epoch 14/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.7100 - val_loss: 0.5608\n",
      "Epoch 15/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6976 - val_loss: 0.5503\n",
      "Epoch 16/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6869 - val_loss: 0.5437\n",
      "Epoch 17/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6769 - val_loss: 0.5319\n",
      "Epoch 18/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6683 - val_loss: 0.5239\n",
      "Epoch 19/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6587 - val_loss: 0.5150\n",
      "Epoch 20/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6514 - val_loss: 0.5102\n",
      "Epoch 21/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6436 - val_loss: 0.5067\n",
      "Epoch 22/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6371 - val_loss: 0.4982\n",
      "Epoch 23/500\n",
      "1247/1247 [==============================] - 95s 77ms/step - loss: 0.6299 - val_loss: 0.4927\n",
      "Epoch 24/500\n",
      "1247/1247 [==============================] - 95s 77ms/step - loss: 0.6229 - val_loss: 0.4866\n",
      "Epoch 25/500\n",
      "1247/1247 [==============================] - 95s 77ms/step - loss: 0.6166 - val_loss: 0.4820\n",
      "Epoch 26/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6114 - val_loss: 0.4805\n",
      "Epoch 27/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6064 - val_loss: 0.4760\n",
      "Epoch 28/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.6007 - val_loss: 0.4700\n",
      "Epoch 29/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5956 - val_loss: 0.4669\n",
      "Epoch 30/500\n",
      "1247/1247 [==============================] - 95s 77ms/step - loss: 0.5907 - val_loss: 0.4630\n",
      "Epoch 31/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5875 - val_loss: 0.4606\n",
      "Epoch 32/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5818 - val_loss: 0.4564\n",
      "Epoch 33/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5785 - val_loss: 0.4538\n",
      "Epoch 34/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5739 - val_loss: 0.4495\n",
      "Epoch 35/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5705 - val_loss: 0.4500\n",
      "Epoch 36/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5668 - val_loss: 0.4458\n",
      "Epoch 37/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5634 - val_loss: 0.4435\n",
      "Epoch 38/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5595 - val_loss: 0.4395\n",
      "Epoch 39/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5566 - val_loss: 0.4364\n",
      "Epoch 40/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5527 - val_loss: 0.4353\n",
      "Epoch 41/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5497 - val_loss: 0.4350\n",
      "Epoch 42/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5475 - val_loss: 0.4281\n",
      "Epoch 43/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5445 - val_loss: 0.4271\n",
      "Epoch 44/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5420 - val_loss: 0.4244\n",
      "Epoch 45/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5388 - val_loss: 0.4264\n",
      "Epoch 46/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5358 - val_loss: 0.4228\n",
      "Epoch 47/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5330 - val_loss: 0.4200\n",
      "Epoch 48/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5315 - val_loss: 0.4190\n",
      "Epoch 49/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5289 - val_loss: 0.4173\n",
      "Epoch 50/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5270 - val_loss: 0.4169\n",
      "Epoch 51/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5244 - val_loss: 0.4135\n",
      "Epoch 52/500\n",
      "1247/1247 [==============================] - 95s 76ms/step - loss: 0.5214 - val_loss: 0.4159\n",
      "Epoch 53/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5200 - val_loss: 0.4105\n",
      "Epoch 54/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5180 - val_loss: 0.4124\n",
      "Epoch 55/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5150 - val_loss: 0.4067\n",
      "Epoch 56/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5132 - val_loss: 0.4093\n",
      "Epoch 57/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5119 - val_loss: 0.4074\n",
      "Epoch 58/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5098 - val_loss: 0.4040\n",
      "Epoch 59/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5080 - val_loss: 0.4045\n",
      "Epoch 60/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5059 - val_loss: 0.4029\n",
      "Epoch 61/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5041 - val_loss: 0.4006\n",
      "Epoch 62/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5022 - val_loss: 0.4003\n",
      "Epoch 63/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.5001 - val_loss: 0.3983\n",
      "Epoch 64/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4997 - val_loss: 0.3961\n",
      "Epoch 65/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4975 - val_loss: 0.3967\n",
      "Epoch 66/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4957 - val_loss: 0.3947\n",
      "Epoch 67/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4937 - val_loss: 0.3938\n",
      "Epoch 68/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4934 - val_loss: 0.3926\n",
      "Epoch 69/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4910 - val_loss: 0.3919\n",
      "Epoch 70/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4896 - val_loss: 0.3920\n",
      "Epoch 71/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4882 - val_loss: 0.3895\n",
      "Epoch 72/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4867 - val_loss: 0.3898\n",
      "Epoch 73/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4851 - val_loss: 0.3885\n",
      "Epoch 74/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4840 - val_loss: 0.3873\n",
      "Epoch 75/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4817 - val_loss: 0.3868\n",
      "Epoch 76/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4816 - val_loss: 0.3866\n",
      "Epoch 77/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4797 - val_loss: 0.3856\n",
      "Epoch 78/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4786 - val_loss: 0.3827\n",
      "Epoch 79/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4781 - val_loss: 0.3832\n",
      "Epoch 80/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4763 - val_loss: 0.3831\n",
      "Epoch 81/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4749 - val_loss: 0.3820\n",
      "Epoch 82/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4741 - val_loss: 0.3809\n",
      "Epoch 83/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4728 - val_loss: 0.3807\n",
      "Epoch 84/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4720 - val_loss: 0.3788\n",
      "Epoch 85/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4706 - val_loss: 0.3776\n",
      "Epoch 86/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4701 - val_loss: 0.3818\n",
      "Epoch 87/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4682 - val_loss: 0.3780\n",
      "Epoch 88/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4684 - val_loss: 0.3777\n",
      "Epoch 89/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4667 - val_loss: 0.3790\n",
      "Epoch 90/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4654 - val_loss: 0.3764\n",
      "Epoch 91/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4645 - val_loss: 0.3750\n",
      "Epoch 92/500\n",
      "1247/1247 [==============================] - 93s 75ms/step - loss: 0.4623 - val_loss: 0.3755\n",
      "Epoch 93/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4632 - val_loss: 0.3736\n",
      "Epoch 94/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4608 - val_loss: 0.3738\n",
      "Epoch 95/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4592 - val_loss: 0.3718\n",
      "Epoch 96/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4594 - val_loss: 0.3739\n",
      "Epoch 97/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4591 - val_loss: 0.3716\n",
      "Epoch 98/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4571 - val_loss: 0.3709\n",
      "Epoch 99/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4572 - val_loss: 0.3726\n",
      "Epoch 100/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4560 - val_loss: 0.3707\n",
      "Epoch 101/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4545 - val_loss: 0.3701\n",
      "Epoch 102/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4537 - val_loss: 0.3677\n",
      "Epoch 103/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4533 - val_loss: 0.3678\n",
      "Epoch 104/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4517 - val_loss: 0.3670\n",
      "Epoch 105/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4512 - val_loss: 0.3672\n",
      "Epoch 106/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4503 - val_loss: 0.3667\n",
      "Epoch 107/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4499 - val_loss: 0.3663\n",
      "Epoch 108/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4494 - val_loss: 0.3667\n",
      "Epoch 109/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4488 - val_loss: 0.3674\n",
      "Epoch 110/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4474 - val_loss: 0.3664\n",
      "Epoch 111/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4468 - val_loss: 0.3638\n",
      "Epoch 112/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4465 - val_loss: 0.3631\n",
      "Epoch 113/500\n",
      "1247/1247 [==============================] - 94s 76ms/step - loss: 0.4451 - val_loss: 0.3623\n",
      "Epoch 114/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4458 - val_loss: 0.3639\n",
      "Epoch 115/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4444 - val_loss: 0.3654\n",
      "Epoch 116/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4438 - val_loss: 0.3623\n",
      "Epoch 117/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4434 - val_loss: 0.3613\n",
      "Epoch 118/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4416 - val_loss: 0.3651\n",
      "Epoch 119/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4372 - val_loss: 0.3621\n",
      "Epoch 120/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4411 - val_loss: 0.3617\n",
      "Epoch 121/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4398 - val_loss: 0.3607\n",
      "Epoch 122/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4393 - val_loss: 0.3607\n",
      "Epoch 123/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4383 - val_loss: 0.3589\n",
      "Epoch 124/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4381 - val_loss: 0.3587\n",
      "Epoch 125/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4371 - val_loss: 0.3588\n",
      "Epoch 126/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4357 - val_loss: 0.3596\n",
      "Epoch 127/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4370 - val_loss: 0.3604\n",
      "Epoch 128/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4345 - val_loss: 0.3533\n",
      "Epoch 129/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4340 - val_loss: 0.3571\n",
      "Epoch 130/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4345 - val_loss: 0.3588\n",
      "Epoch 131/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4338 - val_loss: 0.3570\n",
      "Epoch 132/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4340 - val_loss: 0.3552\n",
      "Epoch 133/500\n",
      "1247/1247 [==============================] - 94s 75ms/step - loss: 0.4331 - val_loss: 0.3553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5960cd24e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "seq2seq_model.fit_generator(train_generator, epochs=500,\n",
    "                            validation_data=valid_generator,\n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoder/decoder models for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder = Model(encoder_in, encoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_in (InputLayer)         (None, None, 101)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mask (Masking)          (None, None, 101)    0           encoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fwd_enc_gru (GRU)               (None, 512)          943104      encoder_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "rev_enc_gru (GRU)               (None, 512)          943104      encoder_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_out (Concatenate)       (None, 1024)         0           fwd_enc_gru[0][0]                \n",
      "                                                                 rev_enc_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,886,208\n",
      "Trainable params: 1,886,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dec_h_in = Input(shape=(decoder_latent_dim,), name=\"decoder_h_in\")\n",
    "\n",
    "inf_dec_gru_out, inf_dec_h_out = decoder_gru(\n",
    "    decoder_in, initial_state=inf_dec_h_in)\n",
    "\n",
    "inf_dec_out = decoder_dense(inf_dec_gru_out)\n",
    "\n",
    "inf_decoder = Model(\n",
    "    [decoder_in, inf_dec_h_in],\n",
    "    [inf_dec_out, inf_dec_h_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_in (InputLayer)         (None, None, 87)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_h_in (InputLayer)       (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 1024), 3416064     decoder_in[0][0]                 \n",
      "                                                                 decoder_h_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_out (Dense)             (None, None, 87)     89175       decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,505,239\n",
      "Trainable params: 3,505,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test trained model on the first 100 samples from both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max output length:  87\n"
     ]
    }
   ],
   "source": [
    "max_out_seq_len = max([len(seq) for _, seq in samples])\n",
    "print(\"Max output length: \", max_out_seq_len)\n",
    "\n",
    "start_token_idx = out_token2int[start_token]\n",
    "stop_token_idx = out_token2int[stop_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(one_hot_seq, encoder, decoder):\n",
    "    encoding = encoder.predict(one_hot_seq)\n",
    "    \n",
    "    decoder_in = np.zeros((1, 1, out_vocab_size), dtype=np.float32)\n",
    "\n",
    "    translated_text = ''\n",
    "    done_decoding = False\n",
    "    decoded_idx = start_token_idx\n",
    "    while not done_decoding:\n",
    "        decoder_in[0, 0, decoded_idx] = 1\n",
    "        decoding, encoding = decoder.predict([decoder_in, encoding])\n",
    "        decoder_in[0, 0, decoded_idx] = 0\n",
    "\n",
    "        decoded_idx = np.argmax(decoding[0, -1, :])\n",
    "        \n",
    "        if decoded_idx == stop_token_idx:\n",
    "            done_decoding = True\n",
    "        else:\n",
    "            translated_text += out_int2token[decoded_idx]\n",
    "\n",
    "        if len(translated_text) >= max_out_seq_len:\n",
    "            done_decoding = True\n",
    "            \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: A todos nos gusta montar en bici.\n",
      "Dataset translation: \tWe all like cycling.\n",
      "\n",
      "Model output: We like to like bicycle.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se rió de todos los chistes de Mary.\n",
      "Dataset translation: \tTom laughed at all of Mary's jokes.\n",
      "\n",
      "Model output: Tom laughed at Mary all the games.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom es un asqueroso.\n",
      "Dataset translation: \tTom is a creep.\n",
      "\n",
      "Model output: Tom is a scream.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu meta en la vida?\n",
      "Dataset translation: \tWhat's your aim in life?\n",
      "\n",
      "Model output: What's your life in the life?\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le escucha, aunque nadie más lo haga.\n",
      "Dataset translation: \tShe listens to him even though no one else does.\n",
      "\n",
      "Model output: She listens to him anything but I don't know.\n",
      "-----------------------------------------\n",
      "Input sentence: Ganar o perder no es la cuestión.\n",
      "Dataset translation: \tIt doesn't matter whether you win or not.\n",
      "\n",
      "Model output: Winning is not to work out the store.\n",
      "-----------------------------------------\n",
      "Input sentence: Es un privilegio conocerte.\n",
      "Dataset translation: \tIt is a privilege to meet you.\n",
      "\n",
      "Model output: It's a pretty concern to ask you.\n",
      "-----------------------------------------\n",
      "Input sentence: Disculpe, se me han caído los palillos.\n",
      "Dataset translation: \tExcuse me, I dropped a chopstick.\n",
      "\n",
      "Model output: I'm sorry, I had my painters.\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un jardín delante de nuestra casa.\n",
      "Dataset translation: \tThere's a garden in front of our house.\n",
      "\n",
      "Model output: There is a good house in the house.\n",
      "-----------------------------------------\n",
      "Input sentence: Corrí alrededor del campo.\n",
      "Dataset translation: \tI ran around the field.\n",
      "\n",
      "Model output: I ran to the country.\n",
      "-----------------------------------------\n",
      "Input sentence: Nunca me he olvidado de ustedes.\n",
      "Dataset translation: \tI've never forgotten you.\n",
      "\n",
      "Model output: I've never forgotten you.\n",
      "-----------------------------------------\n",
      "Input sentence: A él le operaron la pierna izquierda.\n",
      "Dataset translation: \tHe had an operation on his left leg.\n",
      "\n",
      "Model output: He had lost the leg hands.\n",
      "-----------------------------------------\n",
      "Input sentence: He hecho cosas cuestionables.\n",
      "Dataset translation: \tI've done questionable things.\n",
      "\n",
      "Model output: I've done so much things.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy estudiante de la universidad Hyogo.\n",
      "Dataset translation: \tI am a student at Hyogo University.\n",
      "\n",
      "Model output: I'm studying English at the America.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo la impresión de que ella vendrá hoy.\n",
      "Dataset translation: \tI have an idea she will come today.\n",
      "\n",
      "Model output: I have the computer that he'll come today.\n",
      "-----------------------------------------\n",
      "Input sentence: Está estudiando chino.\n",
      "Dataset translation: \tHe's studying Chinese.\n",
      "\n",
      "Model output: He is studying Chinese.\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que va a llover hoy.\n",
      "Dataset translation: \tI think it's going to rain today.\n",
      "\n",
      "Model output: I think it'll rain today.\n",
      "-----------------------------------------\n",
      "Input sentence: Un niño conducía un rebaño de ovejas.\n",
      "Dataset translation: \tA boy was driving a flock of sheep.\n",
      "\n",
      "Model output: A boy came a bad car a boy.\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy escribiendo una carta.\n",
      "Dataset translation: \tI'm writing a letter.\n",
      "\n",
      "Model output: I am writing a letter.\n",
      "-----------------------------------------\n",
      "Input sentence: Te llevaré a nadar.\n",
      "Dataset translation: \tI will take you for a swim.\n",
      "\n",
      "Model output: I'll take you a swim.\n",
      "-----------------------------------------\n",
      "Input sentence: No falta nada.\n",
      "Dataset translation: \tNothing is missing.\n",
      "\n",
      "Model output: There's nothing about.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo le indiqué el camino.\n",
      "Dataset translation: \tI showed him the way.\n",
      "\n",
      "Model output: I told him the way.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué quieres decir?\n",
      "Dataset translation: \tWhatever do you mean?\n",
      "\n",
      "Model output: What do you want to say?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom necesita un cambio de decorado.\n",
      "Dataset translation: \tTom needs a change of scenery.\n",
      "\n",
      "Model output: Tom needs a change of a decision.\n",
      "-----------------------------------------\n",
      "Input sentence: Pártelo a la mitad.\n",
      "Dataset translation: \tCut it in half.\n",
      "\n",
      "Model output: Stop himself.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Ya decidiste qué hacer?\n",
      "Dataset translation: \tHave you decided what to do yet?\n",
      "\n",
      "Model output: Have you decided to do what you do?\n",
      "-----------------------------------------\n",
      "Input sentence: El entusiasmo es contagioso.\n",
      "Dataset translation: \tEnthusiasm is contagious.\n",
      "\n",
      "Model output: The sunsent is interesting.\n",
      "-----------------------------------------\n",
      "Input sentence: Tanto Tom como Mary estudian francés.\n",
      "Dataset translation: \tTom and Mary both study French.\n",
      "\n",
      "Model output: I am Tom French studying French.\n",
      "-----------------------------------------\n",
      "Input sentence: Me gusta oír buena música.\n",
      "Dataset translation: \tI like listening to good music.\n",
      "\n",
      "Model output: I like to hear music very much.\n",
      "-----------------------------------------\n",
      "Input sentence: Muchísimas gracias por el regalo.\n",
      "Dataset translation: \tThank you very much for your gift.\n",
      "\n",
      "Model output: Thank you for the present for the present.\n",
      "-----------------------------------------\n",
      "Input sentence: Tú estás interfiriendo.\n",
      "Dataset translation: \tYou're interfering.\n",
      "\n",
      "Model output: You're interfering.\n",
      "-----------------------------------------\n",
      "Input sentence: Acabo de verlo.\n",
      "Dataset translation: \tI saw him just now.\n",
      "\n",
      "Model output: I just saw him.\n",
      "-----------------------------------------\n",
      "Input sentence: Déjame pensar esto de nuevo.\n",
      "Dataset translation: \tLet me think this over.\n",
      "\n",
      "Model output: Let me think about this again.\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero creer que es así.\n",
      "Dataset translation: \tI'd like to think so.\n",
      "\n",
      "Model output: I want to believe that is is.\n",
      "-----------------------------------------\n",
      "Input sentence: Hagamos lo que dijo Tom.\n",
      "Dataset translation: \tLet's do what Tom said.\n",
      "\n",
      "Model output: Let's tell Tom what he said.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom una vez trabajó en una panadería.\n",
      "Dataset translation: \tTom once worked at a bakery.\n",
      "\n",
      "Model output: Tom was a divorce on a work.\n",
      "-----------------------------------------\n",
      "Input sentence: A ellos les gusta jugar juntos.\n",
      "Dataset translation: \tThey enjoy playing together.\n",
      "\n",
      "Model output: They like to play together.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres ir primero?\n",
      "Dataset translation: \tDo you want to go first?\n",
      "\n",
      "Model output: Do you want to go first?\n",
      "-----------------------------------------\n",
      "Input sentence: Esperamos visitar España este verano.\n",
      "Dataset translation: \tWe are hoping to visit Spain this summer.\n",
      "\n",
      "Model output: We hope to see this Sunday visit.\n",
      "-----------------------------------------\n",
      "Input sentence: No entiendo lo que quiere decir.\n",
      "Dataset translation: \tI don't understand what you mean.\n",
      "\n",
      "Model output: I don't understand what you mean.\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando el agua se congela se vuelve hielo.\n",
      "Dataset translation: \tWhen water freezes it becomes ice.\n",
      "\n",
      "Model output: When he comes back, but it is covered.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Alguna vez has comido insectos?\n",
      "Dataset translation: \tHave you ever eaten insects?\n",
      "\n",
      "Model output: Have you ever eaten the courses?\n",
      "-----------------------------------------\n",
      "Input sentence: Sal del agua.\n",
      "Dataset translation: \tGet out of the water.\n",
      "\n",
      "Model output: Get out of the water.\n",
      "-----------------------------------------\n",
      "Input sentence: Él se quedó en mi hogar por tres semanas.\n",
      "Dataset translation: \tHe stayed at my place for three weeks.\n",
      "\n",
      "Model output: He stayed there for my three weeks.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom hace su mejor esfuerzo.\n",
      "Dataset translation: \tTom is doing his best.\n",
      "\n",
      "Model output: Tom does his best for him.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo estuvo de acuerdo.\n",
      "Dataset translation: \tEverybody was in agreement.\n",
      "\n",
      "Model output: Everyone was agreed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Si quieres tu dinero de vuelta, solo dilo.\n",
      "Dataset translation: \tIf you want your money back, just say so.\n",
      "\n",
      "Model output: If you want my money, I'll blame you alone.\n",
      "-----------------------------------------\n",
      "Input sentence: Nadie me dijo nada.\n",
      "Dataset translation: \tNo one said anything to me.\n",
      "\n",
      "Model output: No one told me anything.\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom le gusta estar rodeado de gente.\n",
      "Dataset translation: \tTom likes having people around.\n",
      "\n",
      "Model output: Tom likes to be proud of people.\n",
      "-----------------------------------------\n",
      "Input sentence: Tu madre se encuentra en estado crítico.\n",
      "Dataset translation: \tYour mother is in critical condition.\n",
      "\n",
      "Model output: Your mother is coming to criminal than crime.\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un gato debajo de la mesa.\n",
      "Dataset translation: \tThere's a cat under the table.\n",
      "\n",
      "Model output: There is a cat on the table.\n",
      "-----------------------------------------\n",
      "Input sentence: Esto no es un sueño.\n",
      "Dataset translation: \tIt isn't a dream.\n",
      "\n",
      "Model output: This isn't a dream.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos son vuestros.\n",
      "Dataset translation: \tThey're yours.\n",
      "\n",
      "Model output: They're yours.\n",
      "-----------------------------------------\n",
      "Input sentence: Mañana, él alunizará.\n",
      "Dataset translation: \tTomorrow he lands on the moon.\n",
      "\n",
      "Model output: He will be here tomorrow.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jugaré contigo.\n",
      "Dataset translation: \tI'll play with you.\n",
      "\n",
      "Model output: I'll play with you.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom está gordo.\n",
      "Dataset translation: \tTom is fat.\n",
      "\n",
      "Model output: Tom is fat.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedo reservar un vuelo a Chicago?\n",
      "Dataset translation: \tCan I reserve a flight to Chicago?\n",
      "\n",
      "Model output: Can I send a Chinese first flight?\n",
      "-----------------------------------------\n",
      "Input sentence: Él asistió a muchas ceremonias.\n",
      "Dataset translation: \tHe attended many ceremonies.\n",
      "\n",
      "Model output: He accepted many people are a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Nos sentamos ahí.\n",
      "Dataset translation: \tWe sat there.\n",
      "\n",
      "Model output: We sat there.\n",
      "-----------------------------------------\n",
      "Input sentence: Es todo.\n",
      "Dataset translation: \tThat is all.\n",
      "\n",
      "Model output: It's all the enemy.\n",
      "-----------------------------------------\n",
      "Input sentence: Su vida está llena de problemas.\n",
      "Dataset translation: \tHis life is full of trouble.\n",
      "\n",
      "Model output: His life is full of problems.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué estás esperando?\n",
      "Dataset translation: \tWhat are you waiting for?\n",
      "\n",
      "Model output: What are you waiting for?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo puedes aguantarlo?\n",
      "Dataset translation: \tHow can you stand it?\n",
      "\n",
      "Model output: How can you stand it?\n",
      "-----------------------------------------\n",
      "Input sentence: María perdió sus lentes de lectura.\n",
      "Dataset translation: \tMary lost her reading glasses.\n",
      "\n",
      "Model output: Mary lost his legs in his legs.\n",
      "-----------------------------------------\n",
      "Input sentence: Ahora lo digo de veras.\n",
      "Dataset translation: \tI mean it this time.\n",
      "\n",
      "Model output: Now I say that again.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos eran hombres conservadores.\n",
      "Dataset translation: \tThey were conservative men.\n",
      "\n",
      "Model output: They were many managers.\n",
      "-----------------------------------------\n",
      "Input sentence: Quisiera una taza de té.\n",
      "Dataset translation: \tI'd like a cup of tea.\n",
      "\n",
      "Model output: I'd like a cup of tea.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intenta esconder?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What are you trying to hide?\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom no le gustó Mary.\n",
      "Dataset translation: \tTom didn't like Mary.\n",
      "\n",
      "Model output: Tom didn't like Mary.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intentáis ocultar?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What are you trying to hide?\n",
      "-----------------------------------------\n",
      "Input sentence: La táctica funcionó.\n",
      "Dataset translation: \tThe tactic worked.\n",
      "\n",
      "Model output: The teacher worked.\n",
      "-----------------------------------------\n",
      "Input sentence: Vine por ustedes.\n",
      "Dataset translation: \tI came for you.\n",
      "\n",
      "Model output: I came for you.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Te debo algo?\n",
      "Dataset translation: \tDo I owe you something?\n",
      "\n",
      "Model output: Do I owe you something?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me ayudas a mover la mesa?\n",
      "Dataset translation: \tCan you help me move the table?\n",
      "\n",
      "Model output: Can you help me wash the table?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom arriesgó su vida para salvar a Mary.\n",
      "Dataset translation: \tTom risked his life to save Mary.\n",
      "\n",
      "Model output: Tom resulted Mary to save his life.\n",
      "-----------------------------------------\n",
      "Input sentence: He comprado aquí durante siglos.\n",
      "Dataset translation: \tI've shopped here for ages.\n",
      "\n",
      "Model output: I bought here for starts for her first station.\n",
      "-----------------------------------------\n",
      "Input sentence: Até a mi perro a un árbol del jardín.\n",
      "Dataset translation: \tI tied my dog to a tree in the garden.\n",
      "\n",
      "Model output: I locked my dog at the dog.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy de Kioto.\n",
      "Dataset translation: \tI'm from Kyoto.\n",
      "\n",
      "Model output: I'm from Kyoto.\n",
      "-----------------------------------------\n",
      "Input sentence: Las niñas no jugarán al tenis mañana.\n",
      "Dataset translation: \tThe girls will not play tennis tomorrow.\n",
      "\n",
      "Model output: The nights will not play tennis tomorrow.\n",
      "-----------------------------------------\n",
      "Input sentence: Todas las mañanas voy de compras.\n",
      "Dataset translation: \tI go shopping every morning.\n",
      "\n",
      "Model output: I all stay the morning.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que plantar árboles en el jardín.\n",
      "Dataset translation: \tI have to plant trees in the garden.\n",
      "\n",
      "Model output: I have to plant the garden in the tree.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para servir o para llevar?\n",
      "Dataset translation: \tFor here, or to go?\n",
      "\n",
      "Model output: Is it for you to do it?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo supiste que iba a pasar eso?\n",
      "Dataset translation: \tHow did you know that was going to happen?\n",
      "\n",
      "Model output: How did you know what would happen to that?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió en un accidente de tráfico.\n",
      "Dataset translation: \tTom died in a traffic accident.\n",
      "\n",
      "Model output: Tom died in a carding accident.\n",
      "-----------------------------------------\n",
      "Input sentence: Ya no estoy casada con Tom.\n",
      "Dataset translation: \tI'm no longer married to Tom.\n",
      "\n",
      "Model output: I'm not married to Tom.\n",
      "-----------------------------------------\n",
      "Input sentence: No es un reloj.\n",
      "Dataset translation: \tIt is not a watch.\n",
      "\n",
      "Model output: It's not a watch.\n",
      "-----------------------------------------\n",
      "Input sentence: Te ayudaré si es posible.\n",
      "Dataset translation: \tI will help you if possible.\n",
      "\n",
      "Model output: I'll help you if I can possibly.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella realmente quería decir el secreto.\n",
      "Dataset translation: \tShe really wanted to tell the secret.\n",
      "\n",
      "Model output: She really wanted to say the secret.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella se tiñó de rubio.\n",
      "Dataset translation: \tShe dyed her hair blonde.\n",
      "\n",
      "Model output: She died of his boy.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has necesitado ayuda alguna vez?\n",
      "Dataset translation: \tHave you ever needed help?\n",
      "\n",
      "Model output: Have you ever needed any help?\n",
      "-----------------------------------------\n",
      "Input sentence: He venido a despedirme.\n",
      "Dataset translation: \tI've come to say goodbye.\n",
      "\n",
      "Model output: I've come to fire me.\n",
      "-----------------------------------------\n",
      "Input sentence: Sé que no es una broma.\n",
      "Dataset translation: \tI know it's not a joke.\n",
      "\n",
      "Model output: I know it's not a joke.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo cocinaré.\n",
      "Dataset translation: \tI'll cook.\n",
      "\n",
      "Model output: I'll cook.\n",
      "-----------------------------------------\n",
      "Input sentence: Fuera de mi propiedad.\n",
      "Dataset translation: \tGet off my property.\n",
      "\n",
      "Model output: Get on my promise.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedes venir un momento?\n",
      "Dataset translation: \tWould you come here a moment?\n",
      "\n",
      "Model output: Can you come a moment?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se ve aburrido.\n",
      "Dataset translation: \tTom looks bored.\n",
      "\n",
      "Model output: Tom looks bored.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Mira! Hay un avión despegando.\n",
      "Dataset translation: \tLook! There's a plane taking off.\n",
      "\n",
      "Model output: Look! There's a lawyer!\n",
      "-----------------------------------------\n",
      "Input sentence: Este libro no es mío.\n",
      "Dataset translation: \tThis book isn't mine.\n",
      "\n",
      "Model output: This book isn't mine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Tom bebe.\n",
      "Dataset translation: \tTom drinks.\n",
      "\n",
      "Model output: Tom drinks.\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando lo oyó, le entraron ganas de llorar.\n",
      "Dataset translation: \tWhen she heard that, she felt like crying.\n",
      "\n",
      "Model output: When he could hear it, but come in crying.\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_util import test_predictions\n",
    "\n",
    "test_predictions(valid_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Después de una larga espera pudimos entrar.\n",
      "Dataset translation: \tWe got in after a long wait.\n",
      "\n",
      "Model output: After a long time, we can get in the world.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo siento, pero es imposible.\n",
      "Dataset translation: \tI'm sorry, but it's impossible.\n",
      "\n",
      "Model output: I'm sorry, but it's impossible.\n",
      "-----------------------------------------\n",
      "Input sentence: Parecía satisfecho.\n",
      "Dataset translation: \tHe looked pleased.\n",
      "\n",
      "Model output: He looked satisfied.\n",
      "-----------------------------------------\n",
      "Input sentence: Saqué el pastel del horno.\n",
      "Dataset translation: \tI took the cake out of the oven.\n",
      "\n",
      "Model output: I took the cake on the hotel.\n",
      "-----------------------------------------\n",
      "Input sentence: Es un trabajo muy difícil.\n",
      "Dataset translation: \tThat's a very tough job.\n",
      "\n",
      "Model output: It's a very difficult job.\n",
      "-----------------------------------------\n",
      "Input sentence: Dijiste que no entendías.\n",
      "Dataset translation: \tYou said you didn't understand.\n",
      "\n",
      "Model output: You said you didn't understand.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo te está esperando.\n",
      "Dataset translation: \tEverybody is waiting for you.\n",
      "\n",
      "Model output: Everybody is waiting for you.\n",
      "-----------------------------------------\n",
      "Input sentence: Recuerdo lo que era.\n",
      "Dataset translation: \tI remember what it was.\n",
      "\n",
      "Model output: I remember what he was.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom aterrizó su helicóptero sobre el techo.\n",
      "Dataset translation: \tTom landed his helicopter on the roof.\n",
      "\n",
      "Model output: Tom rescued his letter of the library.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom pidió direcciones.\n",
      "Dataset translation: \tTom asked for directions.\n",
      "\n",
      "Model output: Tom asked for directions.\n",
      "-----------------------------------------\n",
      "Input sentence: Él tiene una personalidad dócil.\n",
      "Dataset translation: \tHe has a mild nature.\n",
      "\n",
      "Model output: He has a delicious person.\n",
      "-----------------------------------------\n",
      "Input sentence: Hago ejercicios dos horas por día.\n",
      "Dataset translation: \tI exercise for two hours every day.\n",
      "\n",
      "Model output: I exercise for two hours ago.\n",
      "-----------------------------------------\n",
      "Input sentence: No me creerán aunque les jure que es cierto.\n",
      "Dataset translation: \tThey won't believe me even if I swear it is true.\n",
      "\n",
      "Model output: They won't believe that the truth is believed to me.\n",
      "-----------------------------------------\n",
      "Input sentence: He dado el primer paso.\n",
      "Dataset translation: \tI've taken the first step.\n",
      "\n",
      "Model output: I've gone the first prize.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom y yo trabajamos juntos.\n",
      "Dataset translation: \tTom and I work together.\n",
      "\n",
      "Model output: Tom and I work together.\n",
      "-----------------------------------------\n",
      "Input sentence: Él es mucho mejor que tú.\n",
      "Dataset translation: \tHe is much better than you.\n",
      "\n",
      "Model output: He is much better than you.\n",
      "-----------------------------------------\n",
      "Input sentence: Ven cualquier día que quieras.\n",
      "Dataset translation: \tCome on any day you like.\n",
      "\n",
      "Model output: Come any one you want to do.\n",
      "-----------------------------------------\n",
      "Input sentence: El gerente dijo que era culpa tuya.\n",
      "Dataset translation: \tThe manager said it was your fault.\n",
      "\n",
      "Model output: The police was taller than your fault.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió feliz.\n",
      "Dataset translation: \tTom died happy.\n",
      "\n",
      "Model output: Tom died happy.\n",
      "-----------------------------------------\n",
      "Input sentence: Le vi nuevamente.\n",
      "Dataset translation: \tI saw him again.\n",
      "\n",
      "Model output: I saw him again.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella dejó a los niños al cuidado de su tía.\n",
      "Dataset translation: \tShe left her children in her aunt's care.\n",
      "\n",
      "Model output: She left his children at the children.\n",
      "-----------------------------------------\n",
      "Input sentence: El arte no es un lujo, sino una necesidad.\n",
      "Dataset translation: \tArt is not a luxury, but a necessity.\n",
      "\n",
      "Model output: Art is not a big decision, but can swim.\n",
      "-----------------------------------------\n",
      "Input sentence: Había todo tipo de actividades grupales.\n",
      "Dataset translation: \tThere were all sorts of group activities.\n",
      "\n",
      "Model output: There were all the trees and article article.\n",
      "-----------------------------------------\n",
      "Input sentence: Él te aconsejará al respecto.\n",
      "Dataset translation: \tHe will advise you on that matter.\n",
      "\n",
      "Model output: He will advise you about it.\n",
      "-----------------------------------------\n",
      "Input sentence: Tú no eres japonés.\n",
      "Dataset translation: \tYou are not Japanese.\n",
      "\n",
      "Model output: You are not Japanese.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que cocinar la cena hoy.\n",
      "Dataset translation: \tI have to cook dinner today.\n",
      "\n",
      "Model output: I have to cook dinner today.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy mejor.\n",
      "Dataset translation: \tI am better.\n",
      "\n",
      "Model output: I'm better.\n",
      "-----------------------------------------\n",
      "Input sentence: Te queda bien.\n",
      "Dataset translation: \tThat looks good on you.\n",
      "\n",
      "Model output: That looks good at you.\n",
      "-----------------------------------------\n",
      "Input sentence: Cenaremos juntos y luego iremos al teatro.\n",
      "Dataset translation: \tWe'll dine together and then go to the theater.\n",
      "\n",
      "Model output: We'll get the tiger and the time ago.\n",
      "-----------------------------------------\n",
      "Input sentence: Pasemos adentro.\n",
      "Dataset translation: \tLet's step inside.\n",
      "\n",
      "Model output: Let's stop inside.\n",
      "-----------------------------------------\n",
      "Input sentence: No me puedo costear un auto nuevo.\n",
      "Dataset translation: \tI can't afford a new car.\n",
      "\n",
      "Model output: I can't get a car again.\n",
      "-----------------------------------------\n",
      "Input sentence: «¿A qué hora os levantáis?»«A las ocho.»\n",
      "Dataset translation: \t\"What time do you guys wake up?\" \"Eight o'clock.\"\n",
      "\n",
      "Model output: \"What time do you get up?\" \"It's a good car.\"\n",
      "-----------------------------------------\n",
      "Input sentence: Es un error decir mentiras.\n",
      "Dataset translation: \tIt is wrong to tell a lie.\n",
      "\n",
      "Model output: It's a terrible mistake.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos me mostraron muchas fotos hermosas.\n",
      "Dataset translation: \tThey showed me a lot of beautiful photos.\n",
      "\n",
      "Model output: They showed me some many pictures.\n",
      "-----------------------------------------\n",
      "Input sentence: Ojalá pudiera bailar todos los días.\n",
      "Dataset translation: \tI wish I could dance every day.\n",
      "\n",
      "Model output: I wish I could dance every day.\n",
      "-----------------------------------------\n",
      "Input sentence: Intenté escribir con la mano izquierda.\n",
      "Dataset translation: \tI tried writing with my left hand.\n",
      "\n",
      "Model output: I tried to write with his left hand.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jamás te traicionaría.\n",
      "Dataset translation: \tI'd never betray you.\n",
      "\n",
      "Model output: I'd never betray you.\n",
      "-----------------------------------------\n",
      "Input sentence: Tomás canta bastante bien.\n",
      "Dataset translation: \tTom sings quite well.\n",
      "\n",
      "Model output: Tom sings quite well.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo sé conducir un coche, pero Tom no.\n",
      "Dataset translation: \tI can drive a car, but Tom can't.\n",
      "\n",
      "Model output: I know how to drive a car, but Tom can't.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se portó, para ser un principiante.\n",
      "Dataset translation: \tTom did well for a beginner.\n",
      "\n",
      "Model output: Tom became a beginning to be a prisoner.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo traeré de vuelta.\n",
      "Dataset translation: \tI'll bring it back.\n",
      "\n",
      "Model output: I'll bring it back.\n",
      "-----------------------------------------\n",
      "Input sentence: Casi tengo treinta años.\n",
      "Dataset translation: \tI'm almost thirty.\n",
      "\n",
      "Model output: I'm almost thirty.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom observa a Mary.\n",
      "Dataset translation: \tTom watches Mary.\n",
      "\n",
      "Model output: Tom watches Mary.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres verlo?\n",
      "Dataset translation: \tDo you want to see it?\n",
      "\n",
      "Model output: Do you want to see it?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué tiene ella?\n",
      "Dataset translation: \tWhat does she have?\n",
      "\n",
      "Model output: What does he have?\n",
      "-----------------------------------------\n",
      "Input sentence: La mayoría de la gente no lo haría así.\n",
      "Dataset translation: \tMost people wouldn't do that that way.\n",
      "\n",
      "Model output: Most people wouldn't do that what I would do.\n",
      "-----------------------------------------\n",
      "Input sentence: Leí el libro entero.\n",
      "Dataset translation: \tI read the entire book.\n",
      "\n",
      "Model output: I read the book before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Tienes que responder a la pregunta.\n",
      "Dataset translation: \tYou need to answer the question.\n",
      "\n",
      "Model output: You need to answer the question.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has vivido aquí?\n",
      "Dataset translation: \tDid you live here?\n",
      "\n",
      "Model output: Did you live here?\n",
      "-----------------------------------------\n",
      "Input sentence: He decidido hacer eso solo.\n",
      "Dataset translation: \tI've decided to do that by myself.\n",
      "\n",
      "Model output: I've decided to do that by myself.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le vio comerse un sándwich.\n",
      "Dataset translation: \tShe saw him eating a sandwich.\n",
      "\n",
      "Model output: She saw him eat a sandwich.\n",
      "-----------------------------------------\n",
      "Input sentence: No quiero esta camisa.\n",
      "Dataset translation: \tI don't want this shirt.\n",
      "\n",
      "Model output: I don't want this shirt.\n",
      "-----------------------------------------\n",
      "Input sentence: Él se marchó hace diez minutos.\n",
      "Dataset translation: \tHe left ten minutes ago.\n",
      "\n",
      "Model output: He left me ten minutes ago.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Sabes por qué Tom vino aquí hoy?\n",
      "Dataset translation: \tDo you know the reason Tom came here today?\n",
      "\n",
      "Model output: Do you know why Tom came here today?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me podrías pasar la sal, por favor?\n",
      "Dataset translation: \tCould you pass me the salt, please?\n",
      "\n",
      "Model output: Could you please spend the salt with me?\n",
      "-----------------------------------------\n",
      "Input sentence: No le gustan las cosas dulces.\n",
      "Dataset translation: \tHe doesn't care for sweet things.\n",
      "\n",
      "Model output: He doesn't like sweet things.\n",
      "-----------------------------------------\n",
      "Input sentence: Hoy es jueves.\n",
      "Dataset translation: \tToday is Thursday.\n",
      "\n",
      "Model output: Today is yesterday.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom no se ha sentido muy bien recientemente.\n",
      "Dataset translation: \tTom hasn't been very well recently.\n",
      "\n",
      "Model output: Tom hasn't felt very good at reason.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo lo que sé es que él viene de China.\n",
      "Dataset translation: \tAll I know is that he came from China.\n",
      "\n",
      "Model output: All I know what he came from China.\n",
      "-----------------------------------------\n",
      "Input sentence: Dígame cuando desee hacer su orden.\n",
      "Dataset translation: \tTell me when you'd like to order.\n",
      "\n",
      "Model output: Tell me when you will do the room.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Qué perro más grande!\n",
      "Dataset translation: \tWhat a huge dog!\n",
      "\n",
      "Model output: What a big dog!\n",
      "-----------------------------------------\n",
      "Input sentence: Conseguimos llegar allá a tiempo.\n",
      "Dataset translation: \tWe managed to get there on time.\n",
      "\n",
      "Model output: We got to get there at time.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Vete ya!\n",
      "Dataset translation: \tGo away.\n",
      "\n",
      "Model output: Get lost!\n",
      "-----------------------------------------\n",
      "Input sentence: Él me envió una tarjeta de cumpleaños.\n",
      "Dataset translation: \tHe sent me a birthday card.\n",
      "\n",
      "Model output: He sent me a birthday party.\n",
      "-----------------------------------------\n",
      "Input sentence: No te recuerdo.\n",
      "Dataset translation: \tI don't remember you.\n",
      "\n",
      "Model output: I don't remember you.\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero hacerlo tan a menudo como pueda.\n",
      "Dataset translation: \tI want to do that as often as I can.\n",
      "\n",
      "Model output: I want to do it as soon as I can.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para qué se está escondiendo Tom?\n",
      "Dataset translation: \tWhat's Tom hiding for?\n",
      "\n",
      "Model output: What's Tom hiding for?\n",
      "-----------------------------------------\n",
      "Input sentence: Me da una enchinada.\n",
      "Dataset translation: \tIt creeps me out.\n",
      "\n",
      "Model output: I got a chance.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom nunca lastimaría a sus hijos.\n",
      "Dataset translation: \tTom would never hurt his children.\n",
      "\n",
      "Model output: Tom would never hurt his children.\n",
      "-----------------------------------------\n",
      "Input sentence: Consiguió que la máquina funcionara.\n",
      "Dataset translation: \tHe managed to run the machine.\n",
      "\n",
      "Model output: He managed to work the machine.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Bienvenido a tu nuevo hogar!\n",
      "Dataset translation: \tWelcome to your new home.\n",
      "\n",
      "Model output: Welcome to your new house.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo hice esta silla.\n",
      "Dataset translation: \tI made this chair.\n",
      "\n",
      "Model output: I made this chair.\n",
      "-----------------------------------------\n",
      "Input sentence: Te traje café.\n",
      "Dataset translation: \tI brought you some coffee.\n",
      "\n",
      "Model output: I brought you some coffee.\n",
      "-----------------------------------------\n",
      "Input sentence: Má, ¡apúrate! Están todos esperando.\n",
      "Dataset translation: \tMom, hurry up! Everyone's waiting.\n",
      "\n",
      "Model output: Mom, any other person is waiting.\n",
      "-----------------------------------------\n",
      "Input sentence: El viernes es cuando estoy menos ocupado.\n",
      "Dataset translation: \tFriday is when I am least busy.\n",
      "\n",
      "Model output: It's best friend when I will be busy.\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que el tren vendrá pronto.\n",
      "Dataset translation: \tI think the train will come soon.\n",
      "\n",
      "Model output: I think the train will come soon.\n",
      "-----------------------------------------\n",
      "Input sentence: El sombrero estaba sucio por arriba.\n",
      "Dataset translation: \tThe hat was dirty around the top.\n",
      "\n",
      "Model output: The hat was drunk at his store.\n",
      "-----------------------------------------\n",
      "Input sentence: Por favor, hable más rápido.\n",
      "Dataset translation: \tPlease speak more quickly.\n",
      "\n",
      "Model output: Please speak quickly.\n",
      "-----------------------------------------\n",
      "Input sentence: El despertador sonó.\n",
      "Dataset translation: \tThe alarm went off.\n",
      "\n",
      "Model output: The article was deserted.\n",
      "-----------------------------------------\n",
      "Input sentence: Los ricos tienen muchos amigos.\n",
      "Dataset translation: \tThe rich have many friends.\n",
      "\n",
      "Model output: The rich have many friends.\n",
      "-----------------------------------------\n",
      "Input sentence: No confíe en él.\n",
      "Dataset translation: \tDon't trust him.\n",
      "\n",
      "Model output: Don't trust him.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Habló del accidente?\n",
      "Dataset translation: \tDid he mention the accident?\n",
      "\n",
      "Model output: Did he talk about the accident?\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy desempleada.\n",
      "Dataset translation: \tI'm unemployed.\n",
      "\n",
      "Model output: I'm unemployed.\n",
      "-----------------------------------------\n",
      "Input sentence: No todo estudiante tiene un diccionario.\n",
      "Dataset translation: \tNot every student has a dictionary.\n",
      "\n",
      "Model output: Not every student has a dictionary.\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy cerrando mi tienda.\n",
      "Dataset translation: \tI'm closing my store.\n",
      "\n",
      "Model output: I am closing my store.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo un caballo blanco.\n",
      "Dataset translation: \tI've got a white horse.\n",
      "\n",
      "Model output: I have a horse white.\n",
      "-----------------------------------------\n",
      "Input sentence: Debemos cumplir sus órdenes.\n",
      "Dataset translation: \tWe must execute his orders.\n",
      "\n",
      "Model output: We must be on your room.\n",
      "-----------------------------------------\n",
      "Input sentence: Qué será, será.\n",
      "Dataset translation: \tWhatever will be, will be.\n",
      "\n",
      "Model output: Whatever will be, it's being late.\n",
      "-----------------------------------------\n",
      "Input sentence: No parece alegrarse de vernos.\n",
      "Dataset translation: \tHe doesn't look happy to see us.\n",
      "\n",
      "Model output: He doesn't seem to see us to see us.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo firmaré mañana.\n",
      "Dataset translation: \tI'll sign it tomorrow.\n",
      "\n",
      "Model output: I'll sign it tomorrow.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu equipo de fútbol favorito?\n",
      "Dataset translation: \tWhat's your favorite soccer team?\n",
      "\n",
      "Model output: What's your favorite soccer favorite soccer?\n",
      "-----------------------------------------\n",
      "Input sentence: Tu ayuda nos va a ahorrar mucho trabajo.\n",
      "Dataset translation: \tYour help will save us a lot of work.\n",
      "\n",
      "Model output: Your husband will have a lot of work to sue her.\n",
      "-----------------------------------------\n",
      "Input sentence: El niño se ensució las manos.\n",
      "Dataset translation: \tThe boy got his hands dirty.\n",
      "\n",
      "Model output: The boy started his hands.\n",
      "-----------------------------------------\n",
      "Input sentence: Usted debe ser el nuevo profesor.\n",
      "Dataset translation: \tYou must be the new teacher.\n",
      "\n",
      "Model output: You must be the new teacher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: ¿Quién se robó mi canasto con la carne?\n",
      "Dataset translation: \tWho stole my basket with the meat?\n",
      "\n",
      "Model output: Who stole my key to the passport?\n",
      "-----------------------------------------\n",
      "Input sentence: No estaba manejando tan rápido.\n",
      "Dataset translation: \tI wasn't driving all that fast.\n",
      "\n",
      "Model output: I wasn't driving so fast.\n",
      "-----------------------------------------\n",
      "Input sentence: Están muy lejos.\n",
      "Dataset translation: \tThey are very far away.\n",
      "\n",
      "Model output: They're very far.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella hizo un viaje a Europa el mes pasado.\n",
      "Dataset translation: \tShe made a trip to Europe last month.\n",
      "\n",
      "Model output: She made a large train last month.\n",
      "-----------------------------------------\n",
      "Input sentence: No tengo tiempo para juegos.\n",
      "Dataset translation: \tI don't have time for games.\n",
      "\n",
      "Model output: I don't have time for time.\n",
      "-----------------------------------------\n",
      "Input sentence: Compré esta cámara por 25.000 yenes.\n",
      "Dataset translation: \tI bought this camera for 25,000 yen.\n",
      "\n",
      "Model output: I bought this camera, I came for two cameras.\n"
     ]
    }
   ],
   "source": [
    "test_predictions(train_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model in Core ML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_enc_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "\n",
    "coreml_fwd_enc_gru = GRU(latent_dim, name=\"fwd_enc_gru\")\n",
    "coreml_rev_enc_gru = GRU(latent_dim, go_backwards=True, name=\"rev_enc_gru\")\n",
    "\n",
    "coreml_fwd_out = coreml_fwd_enc_gru(coreml_enc_in)\n",
    "coreml_rev_out = coreml_rev_enc_gru(coreml_enc_in)\n",
    "\n",
    "coreml_enc_out = Concatenate(name=\"encoder_out\")([coreml_fwd_out, coreml_rev_out])\n",
    "\n",
    "coreml_encoder_model = Model(coreml_enc_in, coreml_enc_out)\n",
    "coreml_encoder_model.output_layers = coreml_encoder_model._output_layers\n",
    "\n",
    "inf_encoder.save_weights(\"Es2EnBidirGruCharEncoderWeights.h5\")\n",
    "coreml_encoder_model.load_weights(\"Es2EnBidirGruCharEncoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : encoder_in, <keras.engine.input_layer.InputLayer object at 0x7f58da6f3828>\n",
      "1 : fwd_enc_gru, <keras.layers.recurrent.GRU object at 0x7f58da6f3860>\n",
      "2 : rev_enc_gru, <keras.layers.recurrent.GRU object at 0x7f58da6f3908>\n",
      "3 : encoder_out, <keras.layers.merge.Concatenate object at 0x7f58da6f3a20>\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "\n",
    "coreml_encoder = coremltools.converters.keras.convert(\n",
    "    coreml_encoder_model,\n",
    "    input_names=\"oneHotEncodedSeq\",\n",
    "    output_names=\"decodersIntialState\")\n",
    "\n",
    "coreml_encoder.save(\"Es2EnBidirGruCharEncoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_dec_in = Input(shape=(None, out_vocab_size))\n",
    "\n",
    "coreml_dec_gru = GRU(decoder_latent_dim, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "coreml_dec_gru_out, _ = coreml_dec_gru(coreml_dec_in)\n",
    "coreml_dec_dense = Dense(out_vocab_size, activation=\"softmax\")\n",
    "coreml_dec_out = coreml_dec_dense(coreml_dec_gru_out)\n",
    "\n",
    "coreml_decoder_model = Model(coreml_dec_in, coreml_dec_out)\n",
    "coreml_decoder_model.output_layers = coreml_decoder_model._output_layers\n",
    "\n",
    "inf_decoder.save_weights(\"Es2EnBidirGruCharDecoderWeights.h5\")\n",
    "coreml_decoder_model.load_weights(\"Es2EnBidirGruCharDecoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.input_layer.InputLayer object at 0x7f58da21a278>\n",
      "1 : decoder_gru, <keras.layers.recurrent.GRU object at 0x7f58da21a2b0>\n",
      "2 : dense_1, <keras.layers.core.Dense object at 0x7f58da21a4a8>\n",
      "3 : dense_1__activation__, <keras.layers.core.Activation object at 0x7f58da27ee10>\n"
     ]
    }
   ],
   "source": [
    "coreml_decoder = coremltools.converters.keras.convert(\n",
    "    coreml_decoder_model,\n",
    "    input_names=\"encodedChar\",\n",
    "    output_names=\"nextCharProbs\")\n",
    "\n",
    "coreml_decoder.save(\"Es2EnBidirGruCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weights to 16bit floats. This shouldn't hurt performance much, if at all, and it reduces the app's download size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fp16(mlmodel_filename):\n",
    "    basename = mlmodel_filename[:-len(\".mlmodel\")]\n",
    "    spec = coremltools.utils.load_spec(mlmodel_filename)\n",
    "    spec_16bit = \\\n",
    "      coremltools.utils.convert_neural_network_spec_weights_to_fp16(spec)\n",
    "    coremltools.utils.save_spec(spec_16bit, f\"{basename}16Bit.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_fp16(\"Es2EnBidirGruCharEncoder.mlmodel\")\n",
    "convert_to_fp16(\"Es2EnBidirGruCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"esCharToInt.json\", \"w\") as f:\n",
    "    json.dump(in_token2int, f)\n",
    "with open(\"intToEnChar.json\", \"w\") as f:\n",
    "    json.dump(out_int2token, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
